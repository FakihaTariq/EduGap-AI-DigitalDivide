{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77fe69a",
   "metadata": {},
   "source": [
    "\n",
    "# EduGap: AI-Powered Digital Readiness Analyzer\n",
    "\n",
    "**Date:** 2025-07-23\n",
    "\n",
    "This notebook demonstrates the methodology behind **EduGap**, a machine learningâ€“based tool designed to predict digital readiness using demographic features, and assess the effectiveness of interventions based on skill gain.\n",
    "\n",
    "It supports a companion research paper and repository hosted on GitHub.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b5ffe9",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38734bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4271ed41",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa31fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load CSV file\n",
    "data = pd.read_csv(\"edugap_data.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7435ff",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess and Clean the Data\n",
    "This includes handling missing values and standardizing category labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc126fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.dropna(inplace=True)\n",
    "data = data[data['education'] != 'unknown']\n",
    "data['gender'] = data['gender'].str.lower().replace({'male': 'M', 'female': 'F'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdee1b7",
   "metadata": {},
   "source": [
    "### Transform Categorical Data to Numerical Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['gender'] = data['gender'].map({'M': 0, 'F': 1})\n",
    "data['education'] = data['education'].map({'none': 0, 'high school': 1, 'some college': 2, 'associate': 3, 'bachelor': 4, 'master': 5})\n",
    "data['employment'] = data['employment'].map({'unemployed': 0, 'part-time': 1, 'full-time': 2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a026e",
   "metadata": {},
   "source": [
    "Using pre and post training skill scores to create columns to measure skill gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97860878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating columns\n",
    "data['Computer_Gain'] = data['Post_Training_Basic_Computer_Knowledge_Score'] - data['Basic_Computer_Knowledge_Score']\n",
    "data['Internet_Gain'] = data['Post_Training_Internet_Usage_Score'] - data['Internet_Usage_Score']\n",
    "data['Mobile_Gain'] = data['Post_Training_Mobile_Literacy_Score'] - data['Mobile_Literacy_Score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0396fc",
   "metadata": {},
   "source": [
    "## Step 4: Generate Target Labels from Raw Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eea2f6",
   "metadata": {},
   "source": [
    "### Labeling for identifying underserved groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db957191",
   "metadata": {},
   "source": [
    "In order to prepare the data for better analysis, they are turned into binary labels to measure gains as \"Below Average\" (class 0) and \"Above Average\" (class 1). Note: For simplicity purposes, the terms above and below average are used even though the median is used as the splitting point, not the mean. The median is used in order to improve equity and decrease potential skewness of the data and\\or results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Categorize and Labels (Access)\n",
    "data['Computer_Skill_Label'] = data['Basic_Computer_Knowledge_Score'].apply(lambda x: 0 if x <= 25 else 1)\n",
    "data['Internet_Usage_Label'] = data['Internet_Usage_Score'].apply(lambda x: 0 if x <= 25 else 1)\n",
    "data['Mobile_Literacy_Label'] = data['Mobile_Literacy_Score'].apply(lambda x: 0 if x <= 26 else 1)\n",
    "\n",
    "# Categorize and Labels (Skills)\n",
    "data['Computer_Gain_Label'] = data['Basic_Computer_Knowledge_Score'].apply(lambda x: 0 if x <= 25 else 1)\n",
    "data['Internet_Gain_Label'] = data['Internet_Usage_Score'].apply(lambda x: 0 if x <= 25 else 1)\n",
    "data['Mobile_Gain_Label'] = data['Mobile_Literacy_Score'].apply(lambda x: 0 if x <= 26 else 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3395dbcd",
   "metadata": {},
   "source": [
    "### Labeling for model performance improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46c71c",
   "metadata": {},
   "source": [
    "Quantile based labeling was used in a seperate model in order to improve it's performance and abilities to identify underserved or high-risk groups (class 0) better. Median based labeling is better when using analysis and visualizations for equity purposes due to its interpretability and robustness against outliers. Quantile based labeling allows the model to learn patterns better and increase its ability to recognize class 0 (underserved) groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da5ed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize and Labels (Access)\n",
    "data['Computer_Skill_Label'] = data['Basic_Computer_Knowledge_Score'].apply(lambda x: 0 if x <= data['Basic_Computer_Knowledge_Score'].quantile(0.63) else 1)\n",
    "data['Internet_Usage_Label'] = data['Internet_Usage_Score'].apply(lambda x: 0 if x <= data['Internet_Usage_Score'].quantile(0.56) else 1)\n",
    "data['Mobile_Literacy_Label'] = data['Mobile_Literacy_Score'].apply(lambda x: 0 if x <= data['Mobile_Literacy_Score'].quantile(0.69) else 1)\n",
    "\n",
    "# Categorize and Labels (Skills)\n",
    "data['Computer_Gain_Label'] = data['Basic_Computer_Knowledge_Score'].apply(lambda x: 0 if x <= np.quantile(data['Computer_Gain'], .56) else 1)\n",
    "data['Internet_Gain_Label'] = data['Internet_Usage_Score'].apply(lambda x: 0 if x <= np.quantile(data['Internet_Gain'], .55) else 1)\n",
    "data['Mobile_Gain_Label'] = data['Mobile_Literacy_Score'].apply(lambda x: 0 if x <= np.quantile(data['Mobile_Gain'], .6) else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25151865",
   "metadata": {},
   "source": [
    "## Step 5: Create X and Y Variables and Check for Multicollinearity using VIF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31050668",
   "metadata": {},
   "source": [
    "Multicollinearity, or the occurrence of two or more explanatory variables being very highly linearly related which can lead to misleading conclusions. Values above five are generally considered as having high multicollinearity present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c334bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data[['gender', 'age', 'education', 'employment']]\n",
    "y = data[['access_label', 'skills_label']].apply(lambda col: col.astype('category').cat.codes)\n",
    "\n",
    "features = data[[\"Education_Level\", \"Household_Income\", \"Employment_Status\", \"Age_Group\"]]\n",
    "x_df = pd.DataFrame(x, columns=features.columns)\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = x_df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x_df.values, i) for i in range(x_df.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae064be1",
   "metadata": {},
   "source": [
    "## Step 6: Train Random Forest Multi-Output Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068195b",
   "metadata": {},
   "source": [
    "Various different models were tested and their accuracy score and classification metrics were tracked in order to find the most efficient model for the task at hand: MultiOutputClassifier. Different parameters and values were tested, as well, to train the model to perform its best. \n",
    "\n",
    "### Model Configuration\n",
    "- 'n_estimators = 200' to increase the model's robustness\n",
    "- 'max_depth = 15' to prevent overfitting by limiting how deep trees go\n",
    "- 'max_features = 'sqrt'' to improve generalization by adding randomness\n",
    "- 'min_samples_lead = 4' to prevent the model from creating tiny, noisy leaves (overfitting)\n",
    "- 'min_samples_split = 5' to make sure splits are meanigful\n",
    "- 'class_weight =  'balanced'' to ensure both classes are equally represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = MultiOutputClassifier(RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced',\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ce833",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the Modelâ€™s Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Access Label:\", classification_report(y_test.iloc[:, 0], y_pred[:, 0]))\n",
    "print(\"Skills Label:\", classification_report(y_test.iloc[:, 1], y_pred[:, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526c76c",
   "metadata": {},
   "source": [
    "## Step 8: Calculations and Visualizations (Graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffccc27",
   "metadata": {},
   "source": [
    "To identify underserved groups and how to improve future digital divide intervention efforts, functions to calculate amount below \"average\" (the median or middle value) ['averages_calculate'] and graph the top two graphs most below \"average\" ['bar_graph'] were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29755e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and Calculating\n",
    "def averages_calculate(df, group_col, label_col, title_prefix=\"\"):\n",
    "    grouped = df.groupby(group_col)[label_col].value_counts(normalize=True).unstack().fillna(0)\n",
    "    grouped.columns = ['Below Average', 'Above Average']\n",
    "    print(grouped)\n",
    "\n",
    "\n",
    "def bar_graph(df, group_cols, label_col, top_n, title_prefix):\n",
    "    worst_groups = []\n",
    "    proportions = []\n",
    "    for group in group_cols:\n",
    "        grouped = df.groupby(group)[label_col].value_counts(normalize=True).unstack().fillna(0)\n",
    "        grouped.columns = ['Below Average', 'Above Average']\n",
    "        top_worst = grouped['Below Average'].sort_values(ascending=False).head(top_n)\n",
    "        for idx, val in top_worst.items():\n",
    "            worst_groups.append(f\"{group}: {idx}\")\n",
    "            proportions.append(val)\n",
    "    plt.ylabel(\"Proportion Below Average\")\n",
    "    bars = plt.bar(worst_groups, proportions, color='firebrick')\n",
    "    plt.title(f\"{title_prefix} Most Below Average Groups\")\n",
    "    plt.xticks(rotation=25)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
